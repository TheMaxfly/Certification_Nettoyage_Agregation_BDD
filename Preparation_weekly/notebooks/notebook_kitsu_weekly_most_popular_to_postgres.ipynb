{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79e3e86",
   "metadata": {},
   "source": [
    "# Nettoyage & pr√©paration Kitsu Weekly ‚Äî `most_popular.json` ‚Üí PostgreSQL (objectif RAG/LLM)\n",
    "\n",
    "Ce notebook :\n",
    "1. Charge `most_popular.json` (export Kitsu).\n",
    "2. Nettoie / homog√©n√©ise (titres, synopsis, champs JSON).\n",
    "3. Produit deux tables :\n",
    "   - **core** : 1 ligne par ≈ìuvre (`kitsu_id`)\n",
    "   - **snapshot weekly** : pr√©sence d‚Äôune ≈ìuvre dans une liste hebdo (most_popular / trending_weekly / top_publishing)\n",
    "4. Exporte en CSV (robuste pour `\\copy`) et propose une option d‚Äôinsertion via SQLAlchemy.\n",
    "5. (Optionnel) G√©n√®re un `document_text` pr√™t √† vectoriser pour un pipeline RAG.\n",
    "\n",
    "> Donn√©es : `Preparation_weekly/data/most_popular.json` (ou `trending_weekly.json` / `top_publishing.json`).  \n",
    "> Exports : `Preparation_weekly/export/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1bf3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba48dd",
   "metadata": {},
   "source": [
    "## 1) Charger le JSON + meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81562bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'category': 'most_popular',\n",
       "  'source': 'kitsu',\n",
       "  'endpoint': 'manga?sort=popularityRank',\n",
       "  'fetched_at': '2025-12-13T20:32:51+00:00',\n",
       "  'limit': 100,\n",
       "  'offset': 0},\n",
       " 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîß Param√®tres / chemins (tout reste dans `Preparation_weekly/`)\n",
    "REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / \"pyproject.toml\").exists()), Path.cwd())\n",
    "\n",
    "WEEKLY_DIR = REPO_ROOT / \"Preparation_weekly\"\n",
    "DATA_DIR = WEEKLY_DIR / \"data\"\n",
    "OUT_DIR = WEEKLY_DIR / \"export\"  # dossier d√©j√† pr√©sent\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUT_NAME = \"most_popular.json\"  # ou: \"trending_weekly.json\" / \"top_publishing.json\"\n",
    "INPUT_PATH = DATA_DIR / INPUT_NAME\n",
    "assert INPUT_PATH.exists(), f\"Fichier introuvable: {INPUT_PATH.resolve()}\"\n",
    "\n",
    "payload = json.loads(INPUT_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "meta = payload[\"meta\"]\n",
    "items = payload[\"data\"]\n",
    "\n",
    "meta, len(items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57be727",
   "metadata": {},
   "source": [
    "## 2) Fonctions de nettoyage (synopsis + normalisation titres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5baaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ws_re = re.compile(r\"\\s+\")\n",
    "_non_alnum_re = re.compile(r\"[^a-z0-9]+\")\n",
    "\n",
    "def clean_text(s):\n",
    "    # Nettoyage synopsis/texte: unescape HTML, espaces.\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = html.unescape(s)\n",
    "    s = s.replace(\"\\u0000\", \" \")\n",
    "    s = _ws_re.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def norm_title(s):\n",
    "    # Normalisation l√©g√®re (matching): lower, suppression accents, ponctuation -> espaces, collapse espaces\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.lower().strip()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = _non_alnum_re.sub(\" \", s)\n",
    "    s = _ws_re.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def rating_to_10(x):\n",
    "    # Kitsu renvoie souvent une note /100. On convertit vers /10 si n√©cessaire.\n",
    "    if isinstance(x, (int, float)):\n",
    "        return x / 10.0 if x > 10 else float(x)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3e395",
   "metadata": {},
   "source": [
    "## 3) Flatten vers DataFrame `core`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8397271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kitsu_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>status</th>\n",
       "      <th>title_canonical</th>\n",
       "      <th>title_en</th>\n",
       "      <th>title_ja</th>\n",
       "      <th>title_norm_canonical</th>\n",
       "      <th>title_norm_en</th>\n",
       "      <th>title_norm_ja</th>\n",
       "      <th>synopsis_clean</th>\n",
       "      <th>rating_average_10</th>\n",
       "      <th>rating_rank</th>\n",
       "      <th>popularity_rank</th>\n",
       "      <th>categories_json</th>\n",
       "      <th>genres_json</th>\n",
       "      <th>authors_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26004</td>\n",
       "      <td>boku-no-hero-academia</td>\n",
       "      <td>finished</td>\n",
       "      <td>Boku no Hero Academia</td>\n",
       "      <td>My Hero Academia</td>\n",
       "      <td>ÂÉï„ÅÆ„Éí„Éº„É≠„Éº„Ç¢„Ç´„Éá„Éü„Ç¢</td>\n",
       "      <td>boku no hero academia</td>\n",
       "      <td>my hero academia</td>\n",
       "      <td></td>\n",
       "      <td>What would the world be like if 80 percent of ...</td>\n",
       "      <td>8.467</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[Comedy, Super Power, School Life, Action, Sup...</td>\n",
       "      <td>[Comedy, Super Power, School, Action]</td>\n",
       "      <td>[{'name': 'Kouhei Horikoshi', 'role': 'Sc√©nari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7176</td>\n",
       "      <td>tokyo-ghoul-m</td>\n",
       "      <td>finished</td>\n",
       "      <td>Tokyo Ghoul</td>\n",
       "      <td>Tokyo Ghoul</td>\n",
       "      <td>Êù±‰∫¨Âñ∞Á®Æ„Éà„Éº„Ç≠„Éß„Éº„Ç∞„Éº„É´</td>\n",
       "      <td>tokyo ghoul</td>\n",
       "      <td>tokyo ghoul</td>\n",
       "      <td></td>\n",
       "      <td>Shy Ken Kaneki is thrilled to go on a date wit...</td>\n",
       "      <td>8.416</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>[Horror, Drama, Action, Psychological, Mystery...</td>\n",
       "      <td>[Mystery, Supernatural, Psychological, Thrille...</td>\n",
       "      <td>[{'name': 'Sui Ishida', 'role': 'Sc√©nario &amp; De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>one-piece</td>\n",
       "      <td>current</td>\n",
       "      <td>One Piece</td>\n",
       "      <td>One Piece</td>\n",
       "      <td>ONE PIECE</td>\n",
       "      <td>one piece</td>\n",
       "      <td>one piece</td>\n",
       "      <td>one piece</td>\n",
       "      <td>Gol D. Roger was known as the Pirate King, the...</td>\n",
       "      <td>8.505</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[Comedy, Super Power, Fantasy, Action, Friends...</td>\n",
       "      <td>[Comedy, Sports, Super Power, Fantasy, Action,...</td>\n",
       "      <td>[{'name': 'Eiichiro Oda', 'role': 'Sc√©nario &amp; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kitsu_id                   slug    status        title_canonical  \\\n",
       "0     26004  boku-no-hero-academia  finished  Boku no Hero Academia   \n",
       "1      7176          tokyo-ghoul-m  finished            Tokyo Ghoul   \n",
       "2        38              one-piece   current              One Piece   \n",
       "\n",
       "           title_en      title_ja   title_norm_canonical     title_norm_en  \\\n",
       "0  My Hero Academia   ÂÉï„ÅÆ„Éí„Éº„É≠„Éº„Ç¢„Ç´„Éá„Éü„Ç¢  boku no hero academia  my hero academia   \n",
       "1       Tokyo Ghoul  Êù±‰∫¨Âñ∞Á®Æ„Éà„Éº„Ç≠„Éß„Éº„Ç∞„Éº„É´            tokyo ghoul       tokyo ghoul   \n",
       "2         One Piece     ONE PIECE              one piece         one piece   \n",
       "\n",
       "  title_norm_ja                                     synopsis_clean  \\\n",
       "0                What would the world be like if 80 percent of ...   \n",
       "1                Shy Ken Kaneki is thrilled to go on a date wit...   \n",
       "2     one piece  Gol D. Roger was known as the Pirate King, the...   \n",
       "\n",
       "   rating_average_10  rating_rank  popularity_rank  \\\n",
       "0              8.467            8                1   \n",
       "1              8.416           22                2   \n",
       "2              8.505            2                3   \n",
       "\n",
       "                                     categories_json  \\\n",
       "0  [Comedy, Super Power, School Life, Action, Sup...   \n",
       "1  [Horror, Drama, Action, Psychological, Mystery...   \n",
       "2  [Comedy, Super Power, Fantasy, Action, Friends...   \n",
       "\n",
       "                                         genres_json  \\\n",
       "0              [Comedy, Super Power, School, Action]   \n",
       "1  [Mystery, Supernatural, Psychological, Thrille...   \n",
       "2  [Comedy, Sports, Super Power, Fantasy, Action,...   \n",
       "\n",
       "                                        authors_json  \n",
       "0  [{'name': 'Kouhei Horikoshi', 'role': 'Sc√©nari...  \n",
       "1  [{'name': 'Sui Ishida', 'role': 'Sc√©nario & De...  \n",
       "2  [{'name': 'Eiichiro Oda', 'role': 'Sc√©nario & ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for it in items:\n",
    "    titles = it.get(\"titles\") or {}\n",
    "    ratings = it.get(\"ratings\") or {}\n",
    "    popularity = it.get(\"popularity\") or {}\n",
    "    tags = it.get(\"tags\") or {}\n",
    "\n",
    "    row = {\n",
    "        \"kitsu_id\": int(it[\"id\"]),\n",
    "        \"slug\": it.get(\"slug\"),\n",
    "        \"status\": it.get(\"status\"),\n",
    "\n",
    "        \"title_canonical\": titles.get(\"canonical\"),\n",
    "        \"title_en\": titles.get(\"en\"),\n",
    "        \"title_ja\": titles.get(\"ja\"),\n",
    "\n",
    "        \"title_norm_canonical\": norm_title(titles.get(\"canonical\") or \"\"),\n",
    "        \"title_norm_en\": norm_title(titles.get(\"en\") or \"\"),\n",
    "        \"title_norm_ja\": norm_title(titles.get(\"ja\") or \"\"),\n",
    "\n",
    "        \"synopsis_clean\": clean_text(it.get(\"synopsis\") or \"\"),\n",
    "\n",
    "        \"rating_average_10\": rating_to_10(ratings.get(\"average\")),\n",
    "        \"rating_rank\": ratings.get(\"rank\"),\n",
    "        \"popularity_rank\": popularity.get(\"rank\"),\n",
    "\n",
    "        # JSONB : on garde des listes (m√™me si vides)\n",
    "        \"categories_json\": tags.get(\"categories\") or [],\n",
    "        \"genres_json\": tags.get(\"genres\") or [],\n",
    "        \"authors_json\": it.get(\"authors\") or [],\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "df_core = pd.DataFrame(rows)\n",
    "df_core.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70342faf",
   "metadata": {},
   "source": [
    "## 4) Contr√¥les qualit√© (certif-friendly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83968fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_rows': 100,\n",
       " 'kitsu_id_null': 0,\n",
       " 'kitsu_id_dupe': 0,\n",
       " 'missing_authors': 13,\n",
       " 'missing_genres': 12,\n",
       " 'missing_categories': 1,\n",
       " 'empty_synopsis': 0,\n",
       " 'null_title_canonical': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checks = {\n",
    "    \"n_rows\": int(len(df_core)),\n",
    "    \"kitsu_id_null\": int(df_core[\"kitsu_id\"].isna().sum()),\n",
    "    \"kitsu_id_dupe\": int(df_core[\"kitsu_id\"].duplicated().sum()),\n",
    "    \"missing_authors\": int((df_core[\"authors_json\"].apply(len) == 0).sum()),\n",
    "    \"missing_genres\": int((df_core[\"genres_json\"].apply(len) == 0).sum()),\n",
    "    \"missing_categories\": int((df_core[\"categories_json\"].apply(len) == 0).sum()),\n",
    "    \"empty_synopsis\": int((df_core[\"synopsis_clean\"].str.len() == 0).sum()),\n",
    "    \"null_title_canonical\": int(df_core[\"title_canonical\"].isna().sum()),\n",
    "}\n",
    "checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edb52f",
   "metadata": {},
   "source": [
    "## 5) Construire la table `snapshot weekly` (list_name + position + snapshot_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd4c41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_at</th>\n",
       "      <th>list_name</th>\n",
       "      <th>list_position</th>\n",
       "      <th>kitsu_id</th>\n",
       "      <th>list_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-13 20:32:51+00:00</td>\n",
       "      <td>most_popular</td>\n",
       "      <td>1</td>\n",
       "      <td>26004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-13 20:32:51+00:00</td>\n",
       "      <td>most_popular</td>\n",
       "      <td>2</td>\n",
       "      <td>7176</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-13 20:32:51+00:00</td>\n",
       "      <td>most_popular</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-13 20:32:51+00:00</td>\n",
       "      <td>most_popular</td>\n",
       "      <td>4</td>\n",
       "      <td>14916</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-13 20:32:51+00:00</td>\n",
       "      <td>most_popular</td>\n",
       "      <td>5</td>\n",
       "      <td>24147</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                snapshot_at     list_name  list_position  kitsu_id  list_rank\n",
       "0 2025-12-13 20:32:51+00:00  most_popular              1     26004          1\n",
       "1 2025-12-13 20:32:51+00:00  most_popular              2      7176          2\n",
       "2 2025-12-13 20:32:51+00:00  most_popular              3        38          3\n",
       "3 2025-12-13 20:32:51+00:00  most_popular              4     14916          4\n",
       "4 2025-12-13 20:32:51+00:00  most_popular              5     24147          5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot_at = datetime.fromisoformat(meta[\"fetched_at\"].replace(\"Z\", \"+00:00\"))\n",
    "list_name = meta[\"category\"]\n",
    "\n",
    "snap_rows = []\n",
    "for pos, it in enumerate(items, start=1):\n",
    "    pop = it.get(\"popularity\") or {}\n",
    "    snap_rows.append({\n",
    "        \"snapshot_at\": snapshot_at,\n",
    "        \"list_name\": list_name,\n",
    "        \"list_position\": pos,\n",
    "        \"kitsu_id\": int(it[\"id\"]),\n",
    "        \"list_rank\": pop.get(\"rank\"),\n",
    "    })\n",
    "\n",
    "df_snapshot = pd.DataFrame(snap_rows)\n",
    "df_snapshot.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659ad24",
   "metadata": {},
   "source": [
    "## 6) Export CSV (recommand√©) pour `\\copy` PostgreSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7825b030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/maxime/python/certification/preparation_bdd/Preparation_weekly/export/kitsu_series_core__most_popular__2025-12-13.csv'),\n",
       " PosixPath('/home/maxime/python/certification/preparation_bdd/Preparation_weekly/export/kitsu_weekly_snapshot__most_popular__2025-12-13.csv'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exports CSV (pour \\copy Postgres) -> Preparation_weekly/export\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "core_csv = OUT_DIR / f\"kitsu_series_core__{list_name}__{snapshot_at.date()}.csv\"\n",
    "snap_csv = OUT_DIR / f\"kitsu_weekly_snapshot__{list_name}__{snapshot_at.date()}.csv\"\n",
    "\n",
    "# Pour CSV -> JSONB : s√©rialiser les colonnes listes/dicts en JSON texte\n",
    "df_core_out = df_core.copy()\n",
    "for col in [\"categories_json\", \"genres_json\", \"authors_json\"]:\n",
    "    df_core_out[col] = df_core_out[col].apply(lambda x: json.dumps(x, ensure_ascii=False))\n",
    "\n",
    "df_core_out.to_csv(core_csv, index=False)\n",
    "df_snapshot.to_csv(snap_csv, index=False)\n",
    "\n",
    "core_csv, snap_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b752c2",
   "metadata": {},
   "source": [
    "### Exemple `\\copy` c√¥t√© PostgreSQL\n",
    "\n",
    "Recommandation : charger d‚Äôabord en **staging** (colonnes TEXT), puis caster vers les types finaux.\n",
    "\n",
    "```sql\n",
    "\\copy manga.kitsu_series_core_staging FROM '.../kitsu_series_core__most_popular__YYYY-MM-DD.csv'\n",
    "  WITH (FORMAT csv, HEADER true, DELIMITER ',', QUOTE '\"');\n",
    "\n",
    "\\copy manga.kitsu_weekly_snapshot FROM '.../kitsu_weekly_snapshot__most_popular__YYYY-MM-DD.csv'\n",
    "  WITH (FORMAT csv, HEADER true, DELIMITER ',', QUOTE '\"');\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ec09b",
   "metadata": {},
   "source": [
    "## 7) (Optionnel) Insertion directe via SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8992eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sqlalchemy psycopg2-binary\n",
    "# ‚ö†Ô∏è Utile en dev, mais pour une d√©marche 'certif' + robuste : pr√©f√®re staging + SQL d'upsert.\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "# PG_DSN = \"postgresql+psycopg2://USER:PASSWORD@HOST:5432/DBNAME\"\n",
    "# engine = create_engine(PG_DSN)\n",
    "\n",
    "# df_core.to_sql(\"kitsu_series_core_staging\", engine, schema=\"manga\", if_exists=\"replace\", index=False)\n",
    "# df_snapshot.to_sql(\"kitsu_weekly_snapshot\", engine, schema=\"manga\", if_exists=\"append\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16b44e",
   "metadata": {},
   "source": [
    "## 8) (Optionnel) G√©n√©rer `document_text` pr√™t √† vectoriser (RAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc(row) -> str:\n",
    "    authors = \"\"\n",
    "    if isinstance(row.get(\"authors_json\"), list) and row[\"authors_json\"]:\n",
    "        authors = \", \".join(\n",
    "            [a.get(\"name\", \"\").strip() for a in row[\"authors_json\"] if isinstance(a, dict) and a.get(\"name\")]\n",
    "        )\n",
    "\n",
    "    categories = \", \".join(row[\"categories_json\"] or []) if isinstance(row.get(\"categories_json\"), list) else \"\"\n",
    "    genres = \", \".join(row[\"genres_json\"] or []) if isinstance(row.get(\"genres_json\"), list) else \"\"\n",
    "\n",
    "    parts = [\n",
    "        f\"Titre: {row.get('title_canonical','')}\".strip(),\n",
    "        f\"Titre EN: {row.get('title_en','')}\".strip() if row.get(\"title_en\") else \"\",\n",
    "        f\"Titre JA: {row.get('title_ja','')}\".strip() if row.get(\"title_ja\") else \"\",\n",
    "        f\"Statut: {row.get('status','')}\".strip() if row.get(\"status\") else \"\",\n",
    "        f\"Auteurs: {authors}\" if authors else \"\",\n",
    "        f\"Cat√©gories: {categories}\" if categories else \"\",\n",
    "        f\"Genres: {genres}\" if genres else \"\",\n",
    "        \"\",\n",
    "        (row.get(\"synopsis_clean\") or \"\").strip(),\n",
    "    ]\n",
    "    return \"\\n\".join([p for p in parts if p])\n",
    "\n",
    "df_core[\"document_text\"] = df_core.apply(build_doc, axis=1)\n",
    "df_core[[\"kitsu_id\", \"document_text\"]].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b9a44",
   "metadata": {},
   "source": [
    "## 9) Prochaine √©tape (multi-fichiers)\n",
    "\n",
    "Tu peux r√©utiliser exactement la m√™me logique pour :\n",
    "- `top_publishing.json`\n",
    "- `trending_weekly.json`\n",
    "\n",
    "En pratique :\n",
    "1. Concat√©ner `df_snapshot` des 3 fichiers (m√™me sch√©ma)\n",
    "2. Upsert `df_core` dans la table finale `kitsu_series_core` (cl√© `kitsu_id`)\n",
    "3. G√©n√©rer (ou rafra√Æchir) tes documents/embeddings c√¥t√© RAG (avec `document_text` + signaux weekly)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
