{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ac7348",
   "metadata": {},
   "source": [
    "# C3 — Mapping Manga Sanctuary (MS) ↔ Kitsu + Enrichissement série (Postgres-ready, JSONB) — v2 (anti-collisions)\n",
    "\n",
    "## Objectifs\n",
    "- Générer `ms_title_norm` + `ms_titles_exploded` (titre principal + autres titres)\n",
    "- Générer les **2 pivots Kitsu** :\n",
    "  - `kitsu_series_core` (1 ligne / kitsu_id) = référentiel d’enrichissement\n",
    "  - `kitsu_titles_exploded` (multi-lignes / kitsu_id) = index de matching\n",
    "- Matching en 2 passes :\n",
    "  1) **Exact match** sur `title_norm` (avec **gestion des collisions** via score qualité Kitsu)\n",
    "  2) **Fuzzy match** (RapidFuzz) sur les non matchés (seuil conservateur)\n",
    "- Produire :\n",
    "  - `ms_kitsu_map.(csv|parquet)` : table de correspondance (audit : méthode, score, titre matché)\n",
    "  - `ms_series_enriched_plus_kitsu.(csv|parquet)` : MS enrichi par Kitsu (sans écrasement destructif)\n",
    "  - exports de pivots (audit) : `ms_titles_exploded.csv`, `kitsu_series_core.csv`, `kitsu_titles_exploded.csv`\n",
    "  - optionnel : `ms_kitsu_ambiguous.csv` (cas ambigus à vérifier)\n",
    "\n",
    "## Notes\n",
    "- Pas de RAG ici (pas de chunking, pas d’embeddings).\n",
    "- Les colonnes JSON (tags/genres/catégories, autres titres) sont conservées pour stockage **JSONB** dans PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "except Exception:\n",
    "    load_dotenv = None\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c94b7b",
   "metadata": {},
   "source": [
    "## 0) Paramètres (chemins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROJECT ROOT (robuste même si le kernel démarre dans `notebooks/`) ---\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for root in [start, *start.parents]:\n",
    "        if (root / \"pyproject.toml\").exists():\n",
    "            return root\n",
    "    return start\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "\n",
    "if \"load_dotenv\" in globals() and load_dotenv is not None:\n",
    "    load_dotenv(PROJECT_ROOT / \".env\", override=False)\n",
    "\n",
    "def resolve_from_root(p: str) -> Path:\n",
    "    candidate = Path(p).expanduser()\n",
    "    if candidate.is_absolute():\n",
    "        return candidate\n",
    "    return (PROJECT_ROOT / candidate).resolve()\n",
    "\n",
    "# --- INPUTS ---\n",
    "# Override via env/.env si besoin:\n",
    "# - MS_SERIES_CSV=...\n",
    "# - KITSU_CLEAN_CSV=...\n",
    "MS_SERIES_CSV = resolve_from_root(os.getenv(\"MS_SERIES_CSV\", \"out_ms_final/ms_series_enriched.csv\"))\n",
    "KITSU_CLEAN_CSV = resolve_from_root(os.getenv(\"KITSU_CLEAN_CSV\", \"exports/kitsu/kitsu_top_rated_clean.csv\"))\n",
    "\n",
    "# Compat Colab\n",
    "if not MS_SERIES_CSV.exists() and Path(\"/mnt/data/ms_series_enriched.csv\").exists():\n",
    "    MS_SERIES_CSV = Path(\"/mnt/data/ms_series_enriched.csv\")\n",
    "if not KITSU_CLEAN_CSV.exists() and Path(\"/mnt/data/kitsu_top_rated_clean.csv\").exists():\n",
    "    KITSU_CLEAN_CSV = Path(\"/mnt/data/kitsu_top_rated_clean.csv\")\n",
    "\n",
    "if not MS_SERIES_CSV.exists():\n",
    "    raise FileNotFoundError(f\"MS_SERIES_CSV introuvable: {MS_SERIES_CSV} (override via MS_SERIES_CSV)\")\n",
    "if not KITSU_CLEAN_CSV.exists():\n",
    "    raise FileNotFoundError(f\"KITSU_CLEAN_CSV introuvable: {KITSU_CLEAN_CSV} (override via KITSU_CLEAN_CSV)\")\n",
    "\n",
    "# --- OUTPUTS ---\n",
    "# Override via env/.env si besoin:\n",
    "# - C3_OUT_DIR=...\n",
    "OUT_DIR = resolve_from_root(os.getenv(\"C3_OUT_DIR\", \"out_ms_final/c3_ms_kitsu_v2\"))\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAP_CSV  = OUT_DIR / \"ms_kitsu_map.csv\"\n",
    "MAP_PARQ = OUT_DIR / \"ms_kitsu_map.parquet\"\n",
    "\n",
    "MS_PLUS_CSV  = OUT_DIR / \"ms_series_enriched_plus_kitsu.csv\"\n",
    "MS_PLUS_PARQ = OUT_DIR / \"ms_series_enriched_plus_kitsu.parquet\"\n",
    "\n",
    "MS_TITLES_EX_CSV     = OUT_DIR / \"ms_titles_exploded.csv\"\n",
    "KITSU_CORE_CSV       = OUT_DIR / \"kitsu_series_core.csv\"\n",
    "KITSU_TITLES_EX_CSV  = OUT_DIR / \"kitsu_titles_exploded.csv\"\n",
    "AMBIG_CSV            = OUT_DIR / \"ms_kitsu_ambiguous.csv\"  # optionnel\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"MS_SERIES_CSV:\", MS_SERIES_CSV)\n",
    "print(\"KITSU_CLEAN_CSV:\", KITSU_CLEAN_CSV)\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d74c3a",
   "metadata": {},
   "source": [
    "## 1) Dépendances (pyarrow pour Parquet, rapidfuzz pour fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyarrow  # noqa: F401\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"pyarrow requis pour l'export Parquet. Installe-le (ex: pip install -r requirements-dev.txt). \"\n",
    "        f\"Détail: {repr(e)}\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    from rapidfuzz import process, fuzz\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"rapidfuzz requis pour le fuzzy matching. Installe-le (ex: pip install -r requirements-dev.txt). \"\n",
    "        f\"Détail: {repr(e)}\"\n",
    "    )\n",
    "\n",
    "print(\"OK: pyarrow + rapidfuzz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0cc6e",
   "metadata": {},
   "source": [
    "## 2) Lecture + contrôles C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4368367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = pd.read_csv(MS_SERIES_CSV)\n",
    "kitsu = pd.read_csv(KITSU_CLEAN_CSV)\n",
    "\n",
    "print(\"MS series:\", ms.shape, \" | cols:\", len(ms.columns))\n",
    "print(\"Kitsu:\", kitsu.shape, \" | cols:\", len(kitsu.columns))\n",
    "\n",
    "assert \"series_id\" in ms.columns, \"MS: colonne series_id manquante\"\n",
    "assert \"series_title\" in ms.columns, \"MS: colonne series_title manquante\"\n",
    "assert \"kitsu_id\" in kitsu.columns, \"Kitsu: colonne kitsu_id manquante\"\n",
    "\n",
    "assert ms[\"series_id\"].notna().all(), \"MS: series_id contient des NA\"\n",
    "assert ms[\"series_id\"].is_unique, \"MS: series_id doit être unique\"\n",
    "assert kitsu[\"kitsu_id\"].notna().all(), \"Kitsu: kitsu_id contient des NA\"\n",
    "assert kitsu[\"kitsu_id\"].is_unique, \"Kitsu: kitsu_id doit être unique\"\n",
    "\n",
    "ms.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303534b3",
   "metadata": {},
   "source": [
    "## 3) Helpers (normalisation titres + parsing JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_title(s: str) -> str:\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return None\n",
    "    s = str(s).strip().lower()\n",
    "    if not s:\n",
    "        return None\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = s.replace(\"&\", \"and\")\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s or None\n",
    "\n",
    "def try_parse_json_list(x):\n",
    "    # MS peut contenir des listes en string JSON ou repr Python\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    s = str(x).strip()\n",
    "    if s in (\"\", \"[]\", \"nan\", \"None\"):\n",
    "        return []\n",
    "    # JSON strict\n",
    "    try:\n",
    "        v = json.loads(s)\n",
    "        return v if isinstance(v, list) else [v]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # tentative \"python repr\" -> JSON (simple)\n",
    "    try:\n",
    "        s2 = s.replace(\"'\", '\"')\n",
    "        v = json.loads(s2)\n",
    "        return v if isinstance(v, list) else [v]\n",
    "    except Exception:\n",
    "        return [s]\n",
    "\n",
    "def is_empty_list_str(x) -> bool:\n",
    "    # True si vide ou \"[]\"\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return True\n",
    "    s = str(x).strip()\n",
    "    return s in (\"\", \"[]\", \"nan\", \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1ebe2",
   "metadata": {},
   "source": [
    "## 4) MS — ms_title_norm + ms_titles_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604251cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms[\"ms_title_main\"] = ms[\"series_title\"].astype(str)\n",
    "ms[\"ms_title_norm\"] = ms[\"ms_title_main\"].map(norm_title)\n",
    "\n",
    "# autres titres\n",
    "other_col = None\n",
    "for cand in [\"series_other_titles_json\", \"series_other_titles\"]:\n",
    "    if cand in ms.columns:\n",
    "        other_col = cand\n",
    "        break\n",
    "\n",
    "if other_col:\n",
    "    ms[\"_other_titles_list\"] = ms[other_col].map(try_parse_json_list)\n",
    "else:\n",
    "    ms[\"_other_titles_list\"] = [[] for _ in range(len(ms))]\n",
    "\n",
    "# explode titres (main + others)\n",
    "rows = []\n",
    "for _, r in ms[[\"series_id\", \"ms_title_main\", \"ms_title_norm\", \"_other_titles_list\"]].iterrows():\n",
    "    sid = r[\"series_id\"]\n",
    "    if isinstance(r[\"ms_title_norm\"], str) and r[\"ms_title_norm\"]:\n",
    "        rows.append({\"series_id\": sid, \"title_source\": \"main\", \"title\": r[\"ms_title_main\"], \"title_norm\": r[\"ms_title_norm\"]})\n",
    "    for t in r[\"_other_titles_list\"] or []:\n",
    "        tn = norm_title(t)\n",
    "        if tn:\n",
    "            rows.append({\"series_id\": sid, \"title_source\": \"other\", \"title\": str(t), \"title_norm\": tn})\n",
    "\n",
    "ms_titles_ex = pd.DataFrame(rows).drop_duplicates(subset=[\"series_id\", \"title_norm\"])\n",
    "\n",
    "print(\"ms_titles_exploded:\", ms_titles_ex.shape)\n",
    "ms_titles_ex.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b5e9c",
   "metadata": {},
   "source": [
    "## 5) Kitsu — pivots : core + titles_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_norm_primary (fallback si absent)\n",
    "if \"title_norm_primary\" not in kitsu.columns:\n",
    "    kitsu[\"title_norm_primary\"] = kitsu.get(\"title_norm_canonical\")\n",
    "    kitsu.loc[kitsu[\"title_norm_primary\"].isna(), \"title_norm_primary\"] = kitsu.get(\"title_norm_en\")\n",
    "\n",
    "# candidats titres\n",
    "if \"title_candidates_json\" in kitsu.columns:\n",
    "    kitsu[\"_cands\"] = kitsu[\"title_candidates_json\"].map(try_parse_json_list)\n",
    "else:\n",
    "    kitsu[\"_cands\"] = kitsu.apply(\n",
    "        lambda r: [t for t in [r.get(\"title_canonical\"), r.get(\"title_en\"), r.get(\"title_ja\")] if isinstance(t, str) and t.strip()],\n",
    "        axis=1\n",
    "    )\n",
    "kitsu[\"_cands_norm\"] = kitsu[\"_cands\"].map(lambda L: [norm_title(x) for x in (L or []) if norm_title(x)])\n",
    "\n",
    "# Pivot 1 : core (1 ligne / kitsu_id) — référentiel d'enrichissement\n",
    "core_cols = [\n",
    "    \"kitsu_id\",\"slug\",\"status\",\n",
    "    \"title_canonical\",\"title_en\",\"title_ja\",\n",
    "    \"title_norm_primary\",\"title_norm_canonical\",\"title_norm_en\",\"title_norm_ja\",\n",
    "    \"synopsis_clean\",\"rating_average_10\",\"rating_rank\",\"popularity_rank\",\n",
    "    \"categories_json\",\"genres_json\",\"tags_all_json\",\n",
    "]\n",
    "core_cols = [c for c in core_cols if c in kitsu.columns]\n",
    "kitsu_core = kitsu[core_cols].copy()\n",
    "\n",
    "# Pivot 2 : titles_exploded (multi-lignes / kitsu_id) — index de matching\n",
    "rows = []\n",
    "for _, r in kitsu[[\"kitsu_id\",\"_cands\",\"_cands_norm\"]].iterrows():\n",
    "    kid = r[\"kitsu_id\"]\n",
    "    for t, tn in zip(r[\"_cands\"] or [], r[\"_cands_norm\"] or []):\n",
    "        if tn:\n",
    "            rows.append({\"kitsu_id\": kid, \"title\": str(t), \"title_norm\": tn})\n",
    "\n",
    "kitsu_titles_ex = pd.DataFrame(rows).drop_duplicates(subset=[\"kitsu_id\",\"title_norm\"])\n",
    "\n",
    "print(\"kitsu_core:\", kitsu_core.shape)\n",
    "print(\"kitsu_titles_exploded:\", kitsu_titles_ex.shape)\n",
    "kitsu_titles_ex.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4b15d",
   "metadata": {},
   "source": [
    "## 6) Amélioration v2 — score qualité Kitsu (pour départager les collisions exactes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd153d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_empty_jsonish(x) -> bool:\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return False\n",
    "    if isinstance(x, list):\n",
    "        return len(x) > 0\n",
    "    s = str(x).strip()\n",
    "    return s not in (\"\", \"[]\", \"nan\", \"None\")\n",
    "\n",
    "kitsu_quality = kitsu_core[[\"kitsu_id\"]].copy()\n",
    "\n",
    "kitsu_quality[\"has_synopsis\"] = kitsu_core.get(\"synopsis_clean\").fillna(\"\").astype(str).str.strip().ne(\"\")\n",
    "kitsu_quality[\"has_tags\"] = kitsu_core.get(\"tags_all_json\").map(non_empty_jsonish) if \"tags_all_json\" in kitsu_core.columns else False\n",
    "kitsu_quality[\"has_categories\"] = kitsu_core.get(\"categories_json\").map(non_empty_jsonish) if \"categories_json\" in kitsu_core.columns else False\n",
    "kitsu_quality[\"has_genres\"] = kitsu_core.get(\"genres_json\").map(non_empty_jsonish) if \"genres_json\" in kitsu_core.columns else False\n",
    "\n",
    "kitsu_quality[\"popularity_rank\"] = pd.to_numeric(kitsu_core.get(\"popularity_rank\"), errors=\"coerce\")\n",
    "kitsu_quality[\"rating_rank\"] = pd.to_numeric(kitsu_core.get(\"rating_rank\"), errors=\"coerce\")\n",
    "kitsu_quality[\"rating_average_10\"] = pd.to_numeric(kitsu_core.get(\"rating_average_10\"), errors=\"coerce\")\n",
    "\n",
    "# Score stable & simple : favorise la complétude (synopsis/tags) + un peu de note\n",
    "kitsu_quality[\"quality_score\"] = (\n",
    "    kitsu_quality[\"has_synopsis\"].astype(int) * 1000\n",
    "    + kitsu_quality[\"has_tags\"].astype(int) * 100\n",
    "    + kitsu_quality[\"has_categories\"].astype(int) * 30\n",
    "    + kitsu_quality[\"has_genres\"].astype(int) * 20\n",
    "    + kitsu_quality[\"rating_average_10\"].fillna(0) * 2\n",
    ")\n",
    "\n",
    "kitsu_quality.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f9679",
   "metadata": {},
   "source": [
    "## 7) Exact match (title_norm) — v2 anti-collisions (sélection par score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option anti-collisions : ignorer les title_norm trop courts (souvent ambigus)\n",
    "MIN_NORM_LEN = 4\n",
    "ms_titles_ex_f = ms_titles_ex[ms_titles_ex[\"title_norm\"].str.len() >= MIN_NORM_LEN].copy()\n",
    "kitsu_titles_ex_f = kitsu_titles_ex[kitsu_titles_ex[\"title_norm\"].str.len() >= MIN_NORM_LEN].copy()\n",
    "\n",
    "exact = (\n",
    "    ms_titles_ex_f\n",
    "    .merge(kitsu_titles_ex_f, on=\"title_norm\", how=\"inner\", suffixes=(\"_ms\",\"_kitsu\"))\n",
    "    .merge(kitsu_quality, on=\"kitsu_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "# priorité au titre principal MS\n",
    "exact[\"priority\"] = np.where(exact[\"title_source\"] == \"main\", 0, 1)\n",
    "\n",
    "# Tri : priorité main, puis qualité desc, puis ranks asc\n",
    "exact = exact.sort_values(\n",
    "    [\"series_id\", \"priority\", \"quality_score\", \"popularity_rank\", \"rating_rank\"],\n",
    "    ascending=[True, True, False, True, True],\n",
    ")\n",
    "\n",
    "# Un seul match exact par série\n",
    "exact_best = exact.drop_duplicates(subset=[\"series_id\"], keep=\"first\").copy()\n",
    "exact_best[\"match_method\"] = \"exact_title_norm_scored\"\n",
    "exact_best[\"match_score\"] = 100\n",
    "\n",
    "# Audit collisions (combien de candidats par série)\n",
    "collision_stats = exact.groupby(\"series_id\").size().reset_index(name=\"n_exact_candidates\")\n",
    "n_collisions = int((collision_stats[\"n_exact_candidates\"] >= 2).sum())\n",
    "\n",
    "print(\"exact matches:\", len(exact_best), \"/\", ms[\"series_id\"].nunique())\n",
    "print(\"series with collisions (>=2 exact candidates):\", n_collisions)\n",
    "\n",
    "exact_best.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd773525",
   "metadata": {},
   "source": [
    "## 8) Optionnel — Export des cas ambigus à vérifier (preuve C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On marque \"ambigus\" si >=3 candidats exacts (seuil ajustable)\n",
    "AMBIG_THRESHOLD = 3\n",
    "ambig_ids = set(collision_stats.loc[collision_stats[\"n_exact_candidates\"] >= AMBIG_THRESHOLD, \"series_id\"])\n",
    "\n",
    "ms_ambiguous = ms.loc[ms[\"series_id\"].isin(ambig_ids), [\"series_id\",\"ms_title_main\",\"ms_title_norm\"]].copy()\n",
    "ms_ambiguous[\"n_exact_candidates\"] = ms_ambiguous[\"series_id\"].map(\n",
    "    dict(zip(collision_stats[\"series_id\"], collision_stats[\"n_exact_candidates\"]))\n",
    ")\n",
    "\n",
    "print(\"ambiguous series to review:\", len(ms_ambiguous))\n",
    "ms_ambiguous.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ccab1",
   "metadata": {},
   "source": [
    "## 9) Fuzzy match (non-matchés) — rapidfuzz (seuil conservateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_series_ids = set(exact_best[\"series_id\"].tolist())\n",
    "ms_left = ms[~ms[\"series_id\"].isin(matched_series_ids)].copy()\n",
    "\n",
    "# Index fuzzy : compare à title_norm_primary (1 clé par kitsu_id)\n",
    "kitsu_index = kitsu_core[[\"kitsu_id\",\"title_norm_primary\"]].dropna().copy()\n",
    "kitsu_choices = dict(zip(kitsu_index[\"kitsu_id\"].tolist(), kitsu_index[\"title_norm_primary\"].tolist()))\n",
    "\n",
    "FUZZY_MIN_SCORE = 92  # conservateur (baisse si trop peu de match; augmente si faux positifs)\n",
    "\n",
    "fuzzy_rows = []\n",
    "for _, r in ms_left[[\"series_id\",\"ms_title_norm\",\"ms_title_main\"]].iterrows():\n",
    "    sid = r[\"series_id\"]\n",
    "    q = r[\"ms_title_norm\"]\n",
    "    if not isinstance(q, str) or not q:\n",
    "        continue\n",
    "    hit = process.extractOne(q, kitsu_choices, scorer=fuzz.token_sort_ratio, score_cutoff=FUZZY_MIN_SCORE)\n",
    "    if hit:\n",
    "        kitsu_norm, score, kitsu_id = hit[0], hit[1], hit[2]\n",
    "        fuzzy_rows.append({\n",
    "            \"series_id\": sid,\n",
    "            \"kitsu_id\": int(kitsu_id),\n",
    "            \"match_method\": \"fuzzy_title_norm_primary\",\n",
    "            \"match_score\": float(score),\n",
    "            \"matched_title_norm\": kitsu_norm,\n",
    "            \"ms_title_norm\": q,\n",
    "            \"ms_title\": r[\"ms_title_main\"],\n",
    "        })\n",
    "\n",
    "fuzzy = pd.DataFrame(fuzzy_rows)\n",
    "print(\"fuzzy matches:\", len(fuzzy), \"/\", len(ms_left))\n",
    "fuzzy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe6120",
   "metadata": {},
   "source": [
    "## 10) Construire ms_kitsu_map (audit exact + fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact map (audit)\n",
    "map_exact = exact_best[[\"series_id\",\"kitsu_id\",\"match_method\",\"match_score\",\"title_norm\"]].copy()\n",
    "map_exact = map_exact.rename(columns={\"title_norm\":\"matched_title_norm\"})\n",
    "map_exact[\"ms_title\"] = ms.set_index(\"series_id\").loc[map_exact[\"series_id\"], \"ms_title_main\"].values\n",
    "map_exact[\"ms_title_norm\"] = ms.set_index(\"series_id\").loc[map_exact[\"series_id\"], \"ms_title_norm\"].values\n",
    "\n",
    "# Union exact + fuzzy\n",
    "ms_kitsu_map = pd.concat([map_exact, fuzzy], ignore_index=True)\n",
    "\n",
    "# Si double match: garder exact avant fuzzy puis score max\n",
    "ms_kitsu_map[\"method_prio\"] = np.where(ms_kitsu_map[\"match_method\"].str.startswith(\"exact\"), 0, 1)\n",
    "ms_kitsu_map = ms_kitsu_map.sort_values([\"series_id\",\"method_prio\",\"match_score\"], ascending=[True, True, False])\n",
    "ms_kitsu_map = ms_kitsu_map.drop_duplicates(subset=[\"series_id\"], keep=\"first\").drop(columns=[\"method_prio\"])\n",
    "\n",
    "print(\"total matches:\", len(ms_kitsu_map), \"/\", ms[\"series_id\"].nunique())\n",
    "ms_kitsu_map[\"match_method\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721a6ef",
   "metadata": {},
   "source": [
    "## 11) Enrichissement MS (sans écrasement destructif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_plus = (ms\n",
    "           .merge(ms_kitsu_map[[\"series_id\",\"kitsu_id\",\"match_method\",\"match_score\"]], on=\"series_id\", how=\"left\")\n",
    "           .merge(kitsu_core.add_prefix(\"kitsu_\"), left_on=\"kitsu_id\", right_on=\"kitsu_kitsu_id\", how=\"left\"))\n",
    "\n",
    "# synopsis: remplir seulement si MS vide\n",
    "if \"series_synopsis\" in ms_plus.columns and \"kitsu_synopsis_clean\" in ms_plus.columns:\n",
    "    ms_plus[\"series_synopsis_enriched\"] = ms_plus[\"series_synopsis\"]\n",
    "    ms_plus.loc[\n",
    "        ms_plus[\"series_synopsis_enriched\"].isna()\n",
    "        | (ms_plus[\"series_synopsis_enriched\"].astype(str).str.strip() == \"\"),\n",
    "        \"series_synopsis_enriched\"\n",
    "    ] = ms_plus[\"kitsu_synopsis_clean\"]\n",
    "else:\n",
    "    ms_plus[\"series_synopsis_enriched\"] = ms_plus.get(\"series_synopsis\")\n",
    "\n",
    "# tags/genres: si MS est []/vide => remplir via Kitsu\n",
    "if \"series_tags\" in ms_plus.columns and \"kitsu_tags_all_json\" in ms_plus.columns:\n",
    "    ms_plus[\"series_tags_enriched\"] = ms_plus[\"series_tags\"]\n",
    "    empty_mask = ms_plus[\"series_tags_enriched\"].map(is_empty_list_str)\n",
    "    ms_plus.loc[empty_mask, \"series_tags_enriched\"] = ms_plus.loc[empty_mask, \"kitsu_tags_all_json\"]\n",
    "\n",
    "if \"series_genres\" in ms_plus.columns and \"kitsu_genres_json\" in ms_plus.columns:\n",
    "    ms_plus[\"series_genres_enriched\"] = ms_plus[\"series_genres\"]\n",
    "    empty_mask = ms_plus[\"series_genres_enriched\"].map(is_empty_list_str)\n",
    "    ms_plus.loc[empty_mask, \"series_genres_enriched\"] = ms_plus.loc[empty_mask, \"kitsu_genres_json\"]\n",
    "\n",
    "kpi_enrich = {\n",
    "    \"ms_rows\": int(len(ms_plus)),\n",
    "    \"matched_%\": float(ms_plus[\"kitsu_id\"].notna().mean() * 100),\n",
    "    \"synopsis_after_non_empty_%\": float((ms_plus[\"series_synopsis_enriched\"].notna() & (ms_plus[\"series_synopsis_enriched\"].astype(str).str.strip() != \"\")).mean() * 100),\n",
    "}\n",
    "kpi_enrich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec6eda",
   "metadata": {},
   "source": [
    "## 12) Exports CSV + Parquet (JSONB-ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as _json\n",
    "\n",
    "def export_csv_parquet_jsonb(df: pd.DataFrame, csv_path: Path, parq_path: Path, json_cols: list[str]):\n",
    "    # Parquet (pyarrow)\n",
    "    df.to_parquet(parq_path, index=False)\n",
    "\n",
    "    # CSV (garantit strings JSON valides pour les colonnes JSON)\n",
    "    df_csv = df.copy()\n",
    "    for c in json_cols:\n",
    "        if c in df_csv.columns:\n",
    "            def _to_json(v):\n",
    "                if isinstance(v, (list, dict)):\n",
    "                    return _json.dumps(v, ensure_ascii=False)\n",
    "                if v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "                    return \"[]\"\n",
    "                s = str(v).strip()\n",
    "                if s == \"\":\n",
    "                    return \"[]\"\n",
    "                return s\n",
    "            df_csv[c] = df_csv[c].map(_to_json)\n",
    "\n",
    "    df_csv.to_csv(csv_path, index=False)\n",
    "\n",
    "# pivots (audit)\n",
    "ms_titles_ex.to_csv(MS_TITLES_EX_CSV, index=False)\n",
    "kitsu_core.to_csv(KITSU_CORE_CSV, index=False)\n",
    "kitsu_titles_ex.to_csv(KITSU_TITLES_EX_CSV, index=False)\n",
    "\n",
    "# ambiguous (optionnel)\n",
    "if len(ms_ambiguous) > 0:\n",
    "    ms_ambiguous.to_csv(AMBIG_CSV, index=False)\n",
    "    print(\"Wrote:\", AMBIG_CSV)\n",
    "\n",
    "# mapping\n",
    "export_csv_parquet_jsonb(ms_kitsu_map, MAP_CSV, MAP_PARQ, json_cols=[])\n",
    "\n",
    "# ms enrichi: colonnes JSON à conserver JSONB-ready\n",
    "json_cols_plus = []\n",
    "for c in [\n",
    "    \"series_other_titles\",\"series_other_titles_json\",\"series_statuses\",\"series_related_works\",\"series_tags\",\"series_genres\",\n",
    "    \"series_tags_enriched\",\"series_genres_enriched\",\n",
    "    \"kitsu_categories_json\",\"kitsu_genres_json\",\"kitsu_tags_all_json\"\n",
    "]:\n",
    "    if c in ms_plus.columns:\n",
    "        json_cols_plus.append(c)\n",
    "\n",
    "export_csv_parquet_jsonb(ms_plus, MS_PLUS_CSV, MS_PLUS_PARQ, json_cols=json_cols_plus)\n",
    "\n",
    "print(\"Exported:\")\n",
    "print(\" -\", MAP_CSV)\n",
    "print(\" -\", MS_PLUS_CSV)\n",
    "print(\" - pivots:\", MS_TITLES_EX_CSV, KITSU_CORE_CSV, KITSU_TITLES_EX_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4915b16",
   "metadata": {},
   "source": [
    "## 13) Quick checks (preuve C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping methods:\")\n",
    "print(ms_kitsu_map[\"match_method\"].value_counts())\n",
    "\n",
    "print(\"\\nTop 10 lowest fuzzy scores (if any):\")\n",
    "low = (ms_kitsu_map[ms_kitsu_map[\"match_method\"].str.startswith(\"fuzzy\")]\n",
    "       .sort_values(\"match_score\")\n",
    "       .head(10))\n",
    "low[[\"series_id\",\"kitsu_id\",\"match_score\",\"ms_title\",\"matched_title_norm\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
