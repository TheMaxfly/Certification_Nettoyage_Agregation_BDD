{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Étape 2 — Nettoyage Source 2 (Manga Sanctuary Reviews)\n",
        "\n",
        "Objectif (C3) : produire une base **joinable** et **RAG-friendly** à partir de `manga_sanctuary_reviews*.jsonl`.\n",
        "\n",
        "Sorties (dans `out_ms_staging/`) :\n",
        "- `ms_reviews_clean.csv` + `ms_reviews_clean.parquet`\n",
        "- `ms_reviews_rag_ready.csv` + `ms_reviews_rag_ready.parquet` (uniquement les reviews avec texte exploitable)\n",
        "- `ms_reviews_rejected.jsonl` (audit : lignes invalides / corrompues)\n",
        "- `ms_reviews_stats.json` (KPI + preuves)\n",
        "\n",
        "Étapes C3 :\n",
        "1) lecture robuste + `__line__` + rejets\n",
        "2) normalisation types (id, numéro, url, score)\n",
        "3) nettoyage textes (`review_title`, `review_body`, etc.)\n",
        "4) parsing date FR → `review_date_iso`\n",
        "5) dédup (clé `review_url`)\n",
        "6) préparation RAG (`rag_text`, `rag_len`, filtre rag_ready)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Dépendance Parquet (export systématique Parquet + CSV)\n",
        "\n",
        "Ce notebook exporte **toujours** en **CSV** et aussi en **Parquet**.\n",
        "Parquet nécessite `pyarrow` ou `fastparquet`. On tente d'installer `pyarrow` si nécessaire.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PARQUET_READY = True\n"
          ]
        }
      ],
      "source": [
        "def ensure_pyarrow_or_fail():\n",
        "    try:\n",
        "        import pyarrow  # noqa: F401\n",
        "        return True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        import subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyarrow\"])\n",
        "        import pyarrow  # noqa: F401\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\n",
        "            \"Parquet requis mais pyarrow n'est pas disponible. \"\n",
        "            \"Installe-le manuellement: pip install pyarrow. \"\n",
        "            f\"Détail: {repr(e)}\"\n",
        "        )\n",
        "\n",
        "PARQUET_READY = ensure_pyarrow_or_fail()\n",
        "print(\"PARQUET_READY =\", PARQUET_READY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Chemins (input JSONL + outputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAW_PATH = /home/maxime/python/certification/preparation_bdd/data/manga_sanctuary_reviews (1).jsonl\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ROOT = Path.cwd()\n",
        "if not (PROJECT_ROOT / \"data\").exists() and (PROJECT_ROOT.parent / \"data\").exists():\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "\n",
        "def find_raw_jsonl(project_root: Path) -> Path:\n",
        "    candidates = [\n",
        "        project_root / \"data\" / \"manga_sanctuary_reviews (1).jsonl\",\n",
        "        project_root / \"data\" / \"manga_sanctuary_reviews.jsonl\",\n",
        "        project_root / \"data\" / \"manga_sanctuary_reviews(1).jsonl\",\n",
        "        Path(\"/mnt/data/manga_sanctuary_reviews (1).jsonl\"),\n",
        "        Path(\"/mnt/data/manga_sanctuary_reviews.jsonl\"),\n",
        "        Path(\"/mnt/data/manga_sanctuary_reviews(1).jsonl\"),\n",
        "    ]\n",
        "    for p in candidates:\n",
        "        if p.exists():\n",
        "            return p\n",
        "    data_dir = project_root / \"data\"\n",
        "    if data_dir.exists():\n",
        "        for p in data_dir.glob(\"*reviews*.jsonl\"):\n",
        "            return p\n",
        "    raise FileNotFoundError(\"Impossible de trouver manga_sanctuary_reviews*.jsonl (cherché dans data/ et /mnt/data).\")\n",
        "\n",
        "RAW_PATH = find_raw_jsonl(PROJECT_ROOT)\n",
        "print(\"RAW_PATH =\", RAW_PATH)\n",
        "\n",
        "OUT_DIR = PROJECT_ROOT / \"out_ms_staging\"\n",
        "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "REVIEWS_CSV   = OUT_DIR / \"ms_reviews_clean.csv\"\n",
        "REVIEWS_PARQ  = OUT_DIR / \"ms_reviews_clean.parquet\"\n",
        "RAG_CSV       = OUT_DIR / \"ms_reviews_rag_ready.csv\"\n",
        "RAG_PARQ      = OUT_DIR / \"ms_reviews_rag_ready.parquet\"\n",
        "REJECTED_PATH = OUT_DIR / \"ms_reviews_rejected.jsonl\"\n",
        "STATS_PATH    = OUT_DIR / \"ms_reviews_stats.json\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Lecture robuste JSONL + rejets (audit C3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "raw_valid_rows = 6749\n",
            "raw_rejected_rows = 0\n",
            "df shape = (6749, 13)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>series_id</th>\n",
              "      <th>series_title</th>\n",
              "      <th>series_url</th>\n",
              "      <th>volume_number</th>\n",
              "      <th>volume_url</th>\n",
              "      <th>review_url</th>\n",
              "      <th>review_title</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_author</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_type</th>\n",
              "      <th>review_body</th>\n",
              "      <th>__line__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70676</td>\n",
              "      <td>Le quotidien d'une épée maudite</td>\n",
              "      <td>https://www.manga-sanctuary.com/bdd/manga/7067...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>https://www.manga-sanctuary.com/manga-le-quoti...</td>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>Critique Manga Le quotidien d'une épée maudite #1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Tampopo24</td>\n",
              "      <td>mer. 10 mai 2023</td>\n",
              "      <td>Staff</td>\n",
              "      <td>Les titres humoristiques, avec moi, ça passe o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71144</td>\n",
              "      <td>Villageois LVL 999</td>\n",
              "      <td>https://www.manga-sanctuary.com/bdd/manga/7114...</td>\n",
              "      <td>999.0</td>\n",
              "      <td>https://www.manga-sanctuary.com/manga-villageo...</td>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>Critique Manga Villageois LVL 999 #1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>MassLunar</td>\n",
              "      <td>mer. 24 janv. 2024</td>\n",
              "      <td>Staff</td>\n",
              "      <td>Dans un monde de fantasy au passé lointain cur...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64974</td>\n",
              "      <td>Lupin III anthology</td>\n",
              "      <td>https://www.manga-sanctuary.com/bdd/manga/6497...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.manga-sanctuary.com/manga-lupin-ii...</td>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>Critique Manga Lupin III anthology</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Tampopo24</td>\n",
              "      <td>lun. 18 oct. 2021</td>\n",
              "      <td>Staff</td>\n",
              "      <td>﻿﻿﻿Lupin III est un personnage culte au Japon ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  series_id                     series_title  \\\n",
              "0     70676  Le quotidien d'une épée maudite   \n",
              "1     71144               Villageois LVL 999   \n",
              "2     64974              Lupin III anthology   \n",
              "\n",
              "                                          series_url  volume_number  \\\n",
              "0  https://www.manga-sanctuary.com/bdd/manga/7067...            1.0   \n",
              "1  https://www.manga-sanctuary.com/bdd/manga/7114...          999.0   \n",
              "2  https://www.manga-sanctuary.com/bdd/manga/6497...            NaN   \n",
              "\n",
              "                                          volume_url  \\\n",
              "0  https://www.manga-sanctuary.com/manga-le-quoti...   \n",
              "1  https://www.manga-sanctuary.com/manga-villageo...   \n",
              "2  https://www.manga-sanctuary.com/manga-lupin-ii...   \n",
              "\n",
              "                                          review_url  \\\n",
              "0  https://www.manga-sanctuary.com/fiche_serie_cr...   \n",
              "1  https://www.manga-sanctuary.com/fiche_serie_cr...   \n",
              "2  https://www.manga-sanctuary.com/fiche_serie_cr...   \n",
              "\n",
              "                                        review_title  review_score  \\\n",
              "0  Critique Manga Le quotidien d'une épée maudite #1           7.0   \n",
              "1               Critique Manga Villageois LVL 999 #1           7.0   \n",
              "2                 Critique Manga Lupin III anthology           7.0   \n",
              "\n",
              "  review_author         review_date review_type  \\\n",
              "0     Tampopo24    mer. 10 mai 2023       Staff   \n",
              "1     MassLunar  mer. 24 janv. 2024       Staff   \n",
              "2     Tampopo24   lun. 18 oct. 2021       Staff   \n",
              "\n",
              "                                         review_body  __line__  \n",
              "0  Les titres humoristiques, avec moi, ça passe o...         1  \n",
              "1  Dans un monde de fantasy au passé lointain cur...         2  \n",
              "2  ﻿﻿﻿Lupin III est un personnage culte au Japon ...         3  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def read_jsonl_robust(path: Path):\n",
        "    records = []\n",
        "    rejects = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f, start=1):\n",
        "            raw = line.rstrip(\"\\n\")\n",
        "            if not raw.strip():\n",
        "                rejects.append({\"__line__\": i, \"__reason__\": \"empty_line\", \"__raw__\": \"\"})\n",
        "                continue\n",
        "            try:\n",
        "                obj = json.loads(raw)\n",
        "                if not isinstance(obj, dict):\n",
        "                    rejects.append({\"__line__\": i, \"__reason__\": \"not_object\", \"__raw__\": raw[:500]})\n",
        "                    continue\n",
        "                obj[\"__line__\"] = i\n",
        "                records.append(obj)\n",
        "            except Exception as e:\n",
        "                rejects.append({\"__line__\": i, \"__reason__\": \"invalid_json\", \"__error__\": repr(e), \"__raw__\": raw[:500]})\n",
        "    return records, rejects\n",
        "\n",
        "records, rejects = read_jsonl_robust(RAW_PATH)\n",
        "print(\"raw_valid_rows =\", len(records))\n",
        "print(\"raw_rejected_rows =\", len(rejects))\n",
        "\n",
        "# écrire rejets immédiatement (preuve C3)\n",
        "with REJECTED_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for r in rejects:\n",
        "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "df = pd.DataFrame.from_records(records)\n",
        "print(\"df shape =\", df.shape)\n",
        "df.head(3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Contrôle champs obligatoires + dédup `review_url`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kept_after_required_fields = 6749\n",
            "rejected_missing_required = 0\n",
            "dedup_review_url_removed = 0\n"
          ]
        }
      ],
      "source": [
        "# requis minimal\n",
        "REQUIRED_ALWAYS = [\"series_id\", \"review_url\"]\n",
        "# contenu : au moins titre OU body\n",
        "HAS_CONTENT = (df.get(\"review_title\").notna() & (df.get(\"review_title\").astype(str).str.strip() != \"\")) |               (df.get(\"review_body\").notna() & (df.get(\"review_body\").astype(str).str.strip() != \"\"))\n",
        "\n",
        "required_mask = pd.Series(True, index=df.index)\n",
        "for c in REQUIRED_ALWAYS:\n",
        "    required_mask &= df.get(c).notna() & (df.get(c).astype(str).str.strip() != \"\")\n",
        "\n",
        "required_mask &= HAS_CONTENT\n",
        "\n",
        "df_bad = df[~required_mask].copy()\n",
        "df_ok  = df[required_mask].copy()\n",
        "\n",
        "print(\"kept_after_required_fields =\", len(df_ok))\n",
        "print(\"rejected_missing_required =\", len(df_bad))\n",
        "\n",
        "# ajoute ces rejets à l'audit\n",
        "if len(df_bad):\n",
        "    with REJECTED_PATH.open(\"a\", encoding=\"utf-8\") as f:\n",
        "        for rec in df_bad[[\"__line__\"] + [c for c in REQUIRED_ALWAYS if c in df_bad.columns]].to_dict(\"records\"):\n",
        "            rec[\"__reason__\"] = \"missing_required_fields\"\n",
        "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# dédup review_url (on garde la première occurrence)\n",
        "before = len(df_ok)\n",
        "df_ok = df_ok.drop_duplicates(subset=[\"review_url\"], keep=\"first\").copy()\n",
        "print(\"dedup_review_url_removed =\", before - len(df_ok))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Nettoyage texte + normalisation types\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "series_id          Int64\n",
              "volume_number      Int64\n",
              "review_score     Float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_text(x):\n",
        "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
        "        return None\n",
        "    s = str(x).replace(\"\\u00a0\", \" \").strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    if s.lower() in {\"na\", \"n/a\", \"none\", \"null\", \"\"}:\n",
        "        return None\n",
        "    return s\n",
        "\n",
        "TEXT_COLS = [\n",
        "    \"series_title\",\"series_url\",\n",
        "    \"volume_url\",\"review_url\",\n",
        "    \"review_title\",\"review_body\",\"review_author\",\"review_type\",\n",
        "    \"review_date\",  # brut (souvent FR)\n",
        "]\n",
        "for c in TEXT_COLS:\n",
        "    if c in df_ok.columns:\n",
        "        df_ok[c] = df_ok[c].map(clean_text)\n",
        "\n",
        "# types\n",
        "def to_int(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "def to_float(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Float64\")\n",
        "\n",
        "if \"series_id\" in df_ok.columns:\n",
        "    df_ok[\"series_id\"] = to_int(df_ok[\"series_id\"])\n",
        "if \"volume_number\" in df_ok.columns:\n",
        "    df_ok[\"volume_number\"] = to_int(df_ok[\"volume_number\"])\n",
        "if \"review_score\" in df_ok.columns:\n",
        "    df_ok[\"review_score\"] = to_float(df_ok[\"review_score\"])\n",
        "\n",
        "df_ok[[\"series_id\",\"volume_number\",\"review_score\"]].dtypes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Parsing date FR → `review_date_iso` (corrige l’erreur `.dt`)\n",
        "\n",
        "On produit `review_date_parsed` en `datetime64[ns]`, puis `.dt.strftime()` est valide.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "3f2a1287",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_date_iso</th>\n",
              "      <th>review_date_parse_ok</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mer. 10 mai 2023</td>\n",
              "      <td>2023-05-10</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mer. 24 janv. 2024</td>\n",
              "      <td>2024-01-24</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lun. 18 oct. 2021</td>\n",
              "      <td>2021-10-18</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jeu. 26 mars 2009</td>\n",
              "      <td>2009-03-26</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dim. 10 déc. 2017</td>\n",
              "      <td>2017-12-10</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lun. 16 oct. 2017</td>\n",
              "      <td>2017-10-16</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mar. 14 déc. 2021</td>\n",
              "      <td>2021-12-14</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>jeu. 16 oct. 2008</td>\n",
              "      <td>2008-10-16</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mer. 15 oct. 2008</td>\n",
              "      <td>2008-10-15</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mer. 15 oct. 2008</td>\n",
              "      <td>2008-10-15</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          review_date review_date_iso  review_date_parse_ok\n",
              "0    mer. 10 mai 2023      2023-05-10                  True\n",
              "1  mer. 24 janv. 2024      2024-01-24                  True\n",
              "2   lun. 18 oct. 2021      2021-10-18                  True\n",
              "3   jeu. 26 mars 2009      2009-03-26                  True\n",
              "4   dim. 10 déc. 2017      2017-12-10                  True\n",
              "5   lun. 16 oct. 2017      2017-10-16                  True\n",
              "6   mar. 14 déc. 2021      2021-12-14                  True\n",
              "7   jeu. 16 oct. 2008      2008-10-16                  True\n",
              "8   mer. 15 oct. 2008      2008-10-15                  True\n",
              "9   mer. 15 oct. 2008      2008-10-15                  True"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "FR_MONTHS = {\n",
        "    \"janvier\": 1, \"janv\": 1, \"janv.\": 1,\n",
        "    \"février\": 2, \"fevrier\": 2, \"févr\": 2, \"fevr\": 2, \"févr.\": 2, \"fevr.\": 2,\n",
        "    \"mars\": 3,\n",
        "    \"avril\": 4,\n",
        "    \"mai\": 5,\n",
        "    \"juin\": 6,\n",
        "    \"juillet\": 7, \"juil\": 7, \"juil.\": 7,\n",
        "    \"août\": 8, \"aout\": 8,\n",
        "    \"septembre\": 9, \"sept\": 9, \"sept.\": 9,\n",
        "    \"octobre\": 10, \"oct\": 10, \"oct.\": 10,\n",
        "    \"novembre\": 11, \"nov\": 11, \"nov.\": 11,\n",
        "    \"décembre\": 12, \"decembre\": 12, \"déc\": 12, \"dec\": 12, \"déc.\": 12, \"dec.\": 12,\n",
        "}\n",
        "\n",
        "WEEKDAY_PREFIX = re.compile(r\"^(lun|mar|mer|jeu|ven|sam|dim)\\.?\\s+\", re.IGNORECASE)\n",
        "\n",
        "def parse_fr_date_one(s):\n",
        "    if s is None:\n",
        "        return pd.NaT\n",
        "    s = str(s).strip()\n",
        "    if not s:\n",
        "        return pd.NaT\n",
        "\n",
        "    # enlève \"mer. \", \"lun. \", etc.\n",
        "    s = WEEKDAY_PREFIX.sub(\"\", s)\n",
        "\n",
        "    # \"1er\" -> \"1\"\n",
        "    s2 = s.lower().replace(\"1er\", \"1\").strip()\n",
        "\n",
        "    # dd/mm/yyyy ou dd-mm-yyyy\n",
        "    m = re.match(r\"^(\\d{1,2})[\\/-](\\d{1,2})[\\/-](\\d{2,4})$\", s2)\n",
        "    if m:\n",
        "        d, mo, y = int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
        "        if y < 100:\n",
        "            y += 2000\n",
        "        return pd.Timestamp(year=y, month=mo, day=d)\n",
        "\n",
        "    # \"10 mai 2023\" / \"24 janv. 2024\" / \"18 oct. 2021\"\n",
        "    m2 = re.match(r\"^(\\d{1,2})\\s+([a-zéèêëàâîïôöùûüç\\.]+)\\s+(\\d{4})$\", s2)\n",
        "    if m2:\n",
        "        d = int(m2.group(1))\n",
        "        mon = m2.group(2).strip(\".\")\n",
        "        y = int(m2.group(3))\n",
        "        mo = FR_MONTHS.get(mon)\n",
        "        if mo:\n",
        "            return pd.Timestamp(year=y, month=mo, day=d)\n",
        "\n",
        "    # fallback (au cas où)\n",
        "    return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
        "\n",
        "df_ok[\"review_date_parsed\"] = pd.to_datetime(df_ok[\"review_date\"].map(parse_fr_date_one), errors=\"coerce\")\n",
        "df_ok[\"review_date_iso\"] = df_ok[\"review_date_parsed\"].dt.strftime(\"%Y-%m-%d\")\n",
        "df_ok[\"review_date_parse_ok\"] = df_ok[\"review_date_parsed\"].notna()\n",
        "\n",
        "df_ok[[\"review_date\",\"review_date_iso\",\"review_date_parse_ok\"]].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Préparation RAG : `rag_text` + `rag_len` + filtre `rag_ready`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rag_ready_rows = 3187\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_url</th>\n",
              "      <th>rag_len</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_date_iso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>2618</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2023-05-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>2608</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2024-01-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>4385</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2021-10-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>2608</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2017-12-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>3792</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2017-10-16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          review_url  rag_len  review_score  \\\n",
              "0  https://www.manga-sanctuary.com/fiche_serie_cr...     2618           7.0   \n",
              "1  https://www.manga-sanctuary.com/fiche_serie_cr...     2608           7.0   \n",
              "2  https://www.manga-sanctuary.com/fiche_serie_cr...     4385           7.0   \n",
              "4  https://www.manga-sanctuary.com/fiche_serie_cr...     2608           7.0   \n",
              "5  https://www.manga-sanctuary.com/fiche_serie_cr...     3792           7.0   \n",
              "\n",
              "  review_date_iso  \n",
              "0      2023-05-10  \n",
              "1      2024-01-24  \n",
              "2      2021-10-18  \n",
              "4      2017-12-10  \n",
              "5      2017-10-16  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# texte pour embeddings / retrieval\n",
        "title = df_ok.get(\"review_title\").fillna(\"\").astype(str).str.strip() if \"review_title\" in df_ok.columns else \"\"\n",
        "body  = df_ok.get(\"review_body\").fillna(\"\").astype(str).str.strip() if \"review_body\" in df_ok.columns else \"\"\n",
        "\n",
        "df_ok[\"rag_text\"] = (title + \"\\n\\n\" + body).str.strip()\n",
        "# fallback si titre vide\n",
        "df_ok.loc[df_ok[\"rag_text\"].eq(\"\"), \"rag_text\"] = body[df_ok[\"rag_text\"].eq(\"\")]\n",
        "\n",
        "# longueur + filtre\n",
        "df_ok[\"rag_len\"] = df_ok[\"rag_text\"].str.len()\n",
        "MIN_RAG_CHARS = 120  # ajuste si besoin\n",
        "df_ok[\"rag_ready\"] = df_ok[\"rag_len\"] >= MIN_RAG_CHARS\n",
        "\n",
        "reviews_rag = df_ok[df_ok[\"rag_ready\"]].copy()\n",
        "print(\"rag_ready_rows =\", len(reviews_rag))\n",
        "reviews_rag[[\"review_url\",\"rag_len\",\"review_score\",\"review_date_iso\"]].head(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "712995b6",
      "metadata": {},
      "source": [
        "### conversion de volume_number en entier nullable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b0ff003e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dtype volume_number (après conversion) = Int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1     999\n",
              "2    <NA>\n",
              "3    <NA>\n",
              "4       5\n",
              "5       4\n",
              "6       2\n",
              "7       4\n",
              "8       3\n",
              "9       2\n",
              "Name: volume_number, dtype: Int64"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# conversion uniquement (pas d'export ici)\n",
        "df_ok[\"volume_number\"] = pd.to_numeric(df_ok[\"volume_number\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "print(\"dtype volume_number (après conversion) =\", df_ok[\"volume_number\"].dtype)\n",
        "df_ok[\"volume_number\"].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Export systématique CSV + Parquet (et stats)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'raw_valid_rows': 6749,\n",
              " 'raw_rejected_rows': 0,\n",
              " 'kept_after_required_fields': 6749,\n",
              " 'rejected_missing_required': 0,\n",
              " 'dedup_review_url_removed': 0,\n",
              " 'review_score_non_null_%': 98.56,\n",
              " 'review_date_parse_ok_%': 69.79,\n",
              " 'volume_url_non_null_%': 100.0,\n",
              " 'rag_ready_%': 47.22,\n",
              " 'min_rag_chars': 120,\n",
              " 'exports': {'ms_reviews_clean_csv': '/home/maxime/python/certification/preparation_bdd/out_ms_staging/ms_reviews_clean.csv',\n",
              "  'ms_reviews_clean_parquet': '/home/maxime/python/certification/preparation_bdd/out_ms_staging/ms_reviews_clean.parquet',\n",
              "  'ms_reviews_rag_ready_csv': '/home/maxime/python/certification/preparation_bdd/out_ms_staging/ms_reviews_rag_ready.csv',\n",
              "  'ms_reviews_rag_ready_parquet': '/home/maxime/python/certification/preparation_bdd/out_ms_staging/ms_reviews_rag_ready.parquet',\n",
              "  'rejected_jsonl': '/home/maxime/python/certification/preparation_bdd/out_ms_staging/ms_reviews_rejected.jsonl'}}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# garantir le dtype juste avant export final\n",
        "df_ok[\"volume_number\"] = pd.to_numeric(df_ok[\"volume_number\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "\n",
        "# CSV (toujours)\n",
        "df_ok.to_csv(REVIEWS_CSV, index=False)\n",
        "reviews_rag.to_csv(RAG_CSV, index=False)\n",
        "\n",
        "# Parquet (requis, doit réussir sinon on stop)\n",
        "df_ok.to_parquet(REVIEWS_PARQ, index=False)\n",
        "reviews_rag.to_parquet(RAG_PARQ, index=False)\n",
        "\n",
        "# stats/KPI (preuve C3)\n",
        "stats = {\n",
        "    \"raw_valid_rows\": int(len(records)),\n",
        "    \"raw_rejected_rows\": int(len(rejects)),\n",
        "    \"kept_after_required_fields\": int(len(df_ok)),\n",
        "    \"rejected_missing_required\": int(len(df_bad)),\n",
        "    \"dedup_review_url_removed\": int(before - len(df_ok)),\n",
        "    \"review_score_non_null_%\": float(round(df_ok.get(\"review_score\").notna().mean() * 100, 2)) if \"review_score\" in df_ok.columns else None,\n",
        "    \"review_date_parse_ok_%\": float(round(df_ok[\"review_date_parse_ok\"].mean() * 100, 2)),\n",
        "    \"volume_url_non_null_%\": float(round(df_ok.get(\"volume_url\").notna().mean() * 100, 2)) if \"volume_url\" in df_ok.columns else None,\n",
        "    \"rag_ready_%\": float(round(df_ok[\"rag_ready\"].mean() * 100, 2)),\n",
        "    \"min_rag_chars\": int(MIN_RAG_CHARS),\n",
        "    \"exports\": {\n",
        "        \"ms_reviews_clean_csv\": str(REVIEWS_CSV),\n",
        "        \"ms_reviews_clean_parquet\": str(REVIEWS_PARQ),\n",
        "        \"ms_reviews_rag_ready_csv\": str(RAG_CSV),\n",
        "        \"ms_reviews_rag_ready_parquet\": str(RAG_PARQ),\n",
        "        \"rejected_jsonl\": str(REJECTED_PATH),\n",
        "    },\n",
        "}\n",
        "\n",
        "STATS_PATH.write_text(json.dumps(stats, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "stats\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Contrôle final \n",
        "\n",
        "Colonnes clés attendues pour l’agrégation Étape C3 :\n",
        "- `volume_url` (join principal) + fallback `series_id` & `volume_number`\n",
        "- `review_score`, `review_date_iso`\n",
        "- `rag_text` (pour indexation vectorielle)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "missing_expected_columns = []\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>series_id</th>\n",
              "      <th>volume_url</th>\n",
              "      <th>volume_number</th>\n",
              "      <th>review_url</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_date_iso</th>\n",
              "      <th>rag_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70676</td>\n",
              "      <td>https://www.manga-sanctuary.com/manga-le-quoti...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2023-05-10</td>\n",
              "      <td>Critique Manga Le quotidien d'une épée maudite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71144</td>\n",
              "      <td>https://www.manga-sanctuary.com/manga-villageo...</td>\n",
              "      <td>999</td>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2024-01-24</td>\n",
              "      <td>Critique Manga Villageois LVL 999 #1\\n\\nDans u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64974</td>\n",
              "      <td>https://www.manga-sanctuary.com/manga-lupin-ii...</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>https://www.manga-sanctuary.com/fiche_serie_cr...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2021-10-18</td>\n",
              "      <td>Critique Manga Lupin III anthology\\n\\n﻿﻿﻿Lupin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   series_id                                         volume_url  \\\n",
              "0      70676  https://www.manga-sanctuary.com/manga-le-quoti...   \n",
              "1      71144  https://www.manga-sanctuary.com/manga-villageo...   \n",
              "2      64974  https://www.manga-sanctuary.com/manga-lupin-ii...   \n",
              "\n",
              "   volume_number                                         review_url  \\\n",
              "0              1  https://www.manga-sanctuary.com/fiche_serie_cr...   \n",
              "1            999  https://www.manga-sanctuary.com/fiche_serie_cr...   \n",
              "2           <NA>  https://www.manga-sanctuary.com/fiche_serie_cr...   \n",
              "\n",
              "   review_score review_date_iso  \\\n",
              "0           7.0      2023-05-10   \n",
              "1           7.0      2024-01-24   \n",
              "2           7.0      2021-10-18   \n",
              "\n",
              "                                            rag_text  \n",
              "0  Critique Manga Le quotidien d'une épée maudite...  \n",
              "1  Critique Manga Villageois LVL 999 #1\\n\\nDans u...  \n",
              "2  Critique Manga Lupin III anthology\\n\\n﻿﻿﻿Lupin...  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "expected = [\"series_id\",\"volume_url\",\"volume_number\",\"review_url\",\"review_score\",\"review_date_iso\",\"rag_text\"]\n",
        "missing = [c for c in expected if c not in df_ok.columns]\n",
        "print(\"missing_expected_columns =\", missing)\n",
        "\n",
        "df_ok[expected].head(3) if not missing else df_ok.head(3)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
